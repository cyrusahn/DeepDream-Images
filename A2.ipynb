{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb7fbbca",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586174ee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <p><strong>NOTE:</strong></p>\n",
    "    <p>Before you submit this assignment, <strong>make sure everything runs as expected</strong>:</p>\n",
    "    <ol>\n",
    "        <li><strong>restart the kernel</strong> (in the menubar, select <strong>Kernel → Restart</strong>)\n",
    "        <li><strong>run all cells</strong> (in the menubar, select <strong>Cell → Run All</strong>)</li>\n",
    "    </ol>\n",
    "    <p>Make sure to complete every cell that states \"<strong><TT>YOUR CODE HERE</TT></strong>\" or \"<strong><TT>YOUR ANSWER HERE</TT></strong>\".</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h3 style=\"text-decoration:underline;\">Version 2: Changes</h3>\n",
    "    <p>Please view the blue bubbles (similar to the one encapsulating this text) with the heading <strong>Update</strong> for revised instructions, clarifications, or added details.</p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "# Coding Assignment #2: Version 2\n",
    "\n",
    "This assignment involves **classification**. It extends **Coding Assignment #1**, which involved **regression**.\n",
    "\n",
    "You will classify a set of images using simple implementations of classifiers (linear, SVM, and decision tree classifiers) and an ensemble of the three classifiers. Each image will consist of either a cat or a dog. The classifier must correctly label each image as either an image of a *cat* or as an image of a *dog*.\n",
    "![alt text](https://storage.googleapis.com/tfds-data/visualization/fig/cats_vs_dogs-4.0.0.png \"Dogs & Cats Image\")\n",
    "\n",
    "We will then create a more diverse and obfuscated set of test images to evaluate the robustness of the models. Such an obfuscated image could appear as follows:\n",
    "\n",
    "![alt text](https://www.tensorflow.org/tutorials/generative/deepdream_files/output_tEfd00rr0j8Z_0.png \"DeepDreamed Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f28f52",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ddc11c4abc3e7cf9e415ca656705eb50",
     "grade": false,
     "grade_id": "cell-b9d7b5373c1ab669",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Preliminaries & Dependencies\n",
    "\n",
    "You will need to install the following **Python** packages to complete this assignment (you likely already have most of these libraries installed from previous assignments, quizzes, etc.):\n",
    "\n",
    "    pip install matplotlib numpy\n",
    "    pip install sklearn\n",
    "    pip install tensorflow tensorflow-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473486e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cca651a8bf794cacbcc322b3e4e512a0",
     "grade": false,
     "grade_id": "Overview",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Overview\n",
    "\n",
    "We want to determine the difference in a model's performance when evaluated with data that has been altered or obfusctaed to make the task more difficult to perform.\n",
    "\n",
    "The theme of this assignment is *composition* (\"*the principle of progressive disclosure of complexity*\", to borrow from [Keras](https://keras.io/about)). We will extend and build upon the ideas we have previously explored.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aa9a66",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d4f10ac6675668baaca00f0ff9b80972",
     "grade": false,
     "grade_id": "Objectives",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Objectives\n",
    "\n",
    "Access a *real-world* dataset (e.g., used in kaggle.com competitions, etc.) rather than a *toy* dataset.\n",
    "\n",
    "Generate data from existing, actual data (contrast this to generating synthetic data).\n",
    "\n",
    "Download and implement already trained models.\n",
    "\n",
    "Evaluate the robustness of a model by testing it on data that is designed to be more *complex* than the training data.\n",
    "\n",
    "Develop and evaluate ensembles of models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667924e8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "12797154a7dcda9bbc6ac47d61775eb6",
     "grade": false,
     "grade_id": "Data",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Acquire Data\n",
    "\n",
    "We will use the [Cats and Dogs dataset](https://www.tensorflow.org/datasets/catalog/cats_vs_dogs) (size: 786.7 Mb).\n",
    "The dataset consists of images (the input) and labels, either *cat* or *dog* (the output).\n",
    "Information on the dataset is [here](https://www.microsoft.com/en-us/download/details.aspx?id=54765).\n",
    "\n",
    "Our **goal** is to predict which of two labels (*cat* or *dog*) to apply to an image. This is a binary classification task (i.e., *two categories, two labels, two classes*, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbca59d6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "873eb047604372789dd6723cb7ffb846",
     "grade": false,
     "grade_id": "DownloadingData",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Downlading a dataset (https://www.tensorflow.org/tutorials/images/data_augmentation#apply_augmentation_to_a_dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4917bc6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "233697475c6eb1385e500db32ba7f4e8",
     "grade": false,
     "grade_id": "cell-e638479ac5283c7b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "(train_datasets, val_ds, test_ds), metadata = tfds.load(\n",
    "    'tf_flowers',\n",
    "    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],\n",
    "    with_info=True,\n",
    "    as_supervised=True,\n",
    ")\n",
    "\n",
    "f, y = (features, output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca37057b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d127515fa990cd881df1c91c9e0b8e24",
     "grade": false,
     "grade_id": "DataAugmentation",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Transforming Data\n",
    "\n",
    "We will essentially **augment** our dataset. Augmenting data \"*increases the diversity of your training set by applying random (but realistic) transformations such as image rotation*\" (https://www.tensorflow.org/tutorials/images/data_augmentation).\n",
    "\n",
    "In our case we are *not* augmenting the data to collect more diverse **training data** but to *evaluate* the models on more diverse/complex **testing data**. Thus we will **only** transform the **test data**.\n",
    "\n",
    "\n",
    "\n",
    "## Examples Of Data Augmentation\n",
    "\n",
    "We will be doing something similar to:\n",
    "https://www.tensorflow.org/datasets/catalog/moving_mnist\n",
    "where the MNIST hadwritten digit image dataset was transformed into a video of animated/moving handwritten digits (click *Display Examples* to view the videos).\n",
    "\n",
    "Augmenting a dataset of flower images:\n",
    "https://www.tensorflow.org/tutorials/images/data_augmentation#using_tfimage\n",
    "which uses warping and colour transformations on flower pictures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6743385d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c6ac6bd2e3560eccbd010d5f886a348f",
     "grade": false,
     "grade_id": "TransformDataset",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Example Image Transformations\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>NOTE</h4>\n",
    "    This resize_and_rescale function example is provided for your information. We will <strong>not</strong> be using the code in this example.\n",
    "</div>\n",
    "\n",
    "The code (taken from **Tensorflow**'s explanation for [transforming an image dataset](https://www.tensorflow.org/tutorials/images/data_augmentation#apply_augmentation_to_a_dataset)) is to show how simple the image processing step is.\n",
    "\n",
    "\n",
    "Create a function that resizes and rescales the images (so as to \"*unify the size and scale of images in the dataset*\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633f68e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_rescale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n",
    "    image = (image / 255.0)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45d0a8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fd6950c0f3a04ab2ffb5b4d02dede25e",
     "grade": false,
     "grade_id": "cell-2a1dfe409d1ddfd7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h4>NOTE</h4>\n",
    "    This example (the augment function) is provided for your information. We will <strong>not</strong> be using the code in this example.\n",
    "</div>\n",
    "\n",
    "Create an *augment* function that applies random transformations to an image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d876e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment(image_label, seed):\n",
    "    image, label = image_label\n",
    "    image, label = resize_and_rescale(image, label)\n",
    "    image = tf.image.resize_with_crop_or_pad(image, IMG_SIZE + 6, IMG_SIZE + 6)\n",
    "    \n",
    "    # Make a new seed\n",
    "    new_seed = tf.random.experimental.stateless_split(seed, num=1)[0, :]\n",
    "    \n",
    "    # Random crop back to the original size\n",
    "    image = tf.image.stateless_random_crop(image, size=[IMG_SIZE, IMG_SIZE, 3], seed=seed)\n",
    "    \n",
    "    # Random brightness\n",
    "    image = tf.image.stateless_random_brightness(image, max_delta=0.5, seed=new_seed)\n",
    "    \n",
    "    image = tf.clip_by_value(image, 0, 1)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017565f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5e44869991b09d69e03045454176bdde",
     "grade": false,
     "grade_id": "StylisticAugment",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Stylistic Transformation\n",
    "\n",
    "We will transform the image data *stylistically* by processing images with [**DeepDream**](https://www.tensorflow.org/tutorials/generative/deepdream).\n",
    "\n",
    "For example, this image of a labrador:\n",
    "\n",
    "![alt text](https://www.tensorflow.org/tutorials/generative/deepdream_files/output_Y5BPgc8NNbG0_0.png \"Original Image\")\n",
    "\n",
    "transforms into the following image after being processed by **DeepDream**:\n",
    "\n",
    "![alt text](https://www.tensorflow.org/tutorials/generative/deepdream_files/output_tEfd00rr0j8Z_0.png \"DeepDreamed Image\")\n",
    "\n",
    "A description and tutorial implementation of **Deep Dream** (aka **Inceptionism**) is [here](https://www.tensorflow.org/tutorials/generative/deepdream). Another type of transformation we could have applied to the images was a [Style Transfer](https://www.tensorflow.org/tutorials/generative/style_transfer).\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>NOTE</h4>\n",
    "    We are <strong>not</strong> concerned with the details of <strong>DeepDream</strong>. We will use it as an off-the-shelf component in our system to augment our image dataset for evaluating how a model performs on the <strong>DeepDreamed</strong> images.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9168a287",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7404e48fd55da7bb62197e29f30bda96",
     "grade": false,
     "grade_id": "Imports",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h4>Code To Execute Begins Here</h4>\n",
    "</div>\n",
    "\n",
    "## Imports\n",
    "\n",
    "Import the following libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f652f47",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "831809e6d9d91e7666eac7ddc4b87c4f",
     "grade": false,
     "grade_id": "ImportsCode",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import IPython.display as display\n",
    "import PIL.Image\n",
    "from tensorflow.keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85df129e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "63747e754e2ac8b13fb86ef03aef9d64",
     "grade": false,
     "grade_id": "DeepDream-ImagePrep",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Image Preparation\n",
    "\n",
    "**DeepDream**'s image preparation (code is from https://www.tensorflow.org/tutorials/generative/deepdream#choose_an_image_to_dream-ify):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387412cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "81ae6ae22ce3d8015a74e22d24962889",
     "grade": false,
     "grade_id": "DeepDream-ImagePrepCode",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Download an image and read it into a NumPy array.\n",
    "def download(url, max_dim=None):\n",
    "    name = url.split('/')[-1]\n",
    "    image_path = tf.keras.utils.get_file(name, origin=url)\n",
    "    img = PIL.Image.open(image_path)\n",
    "    if max_dim:\n",
    "        img.thumbnail((max_dim, max_dim))\n",
    "    return np.array(img)\n",
    "\n",
    "# Normalize an image\n",
    "def deprocess(img):\n",
    "    img = 255*(img + 1.0)/2.0\n",
    "    return tf.cast(img, tf.uint8)\n",
    "\n",
    "# Display an image\n",
    "def show(img):\n",
    "    display.display(PIL.Image.fromarray(np.array(img)))\n",
    "\n",
    "# image we will process\n",
    "url = 'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg'\n",
    "\n",
    "# Downsizing the image makes it easier to work with.\n",
    "original_img = download(url, max_dim=500)\n",
    "show(original_img)\n",
    "display.display(display.HTML('Image cc-by: <a \"href=https://commons.wikimedia.org/wiki/File:Felis_catus-cat_on_snow.jpg\">Von.grzanka</a>'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0997d4",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "fadaf26630924189972d51e2d9735c06",
     "grade": false,
     "grade_id": "DownloadPreTrainedModel",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Download Pre-Trained Model\n",
    "\n",
    "Download the [pre-trained model **InceptionV3**](https://keras.io/api/applications/inceptionv3) (size: **92 Mb**).\n",
    "\n",
    "FYI other pre-trained models are available here:\n",
    "https://keras.io/api/applications/#available-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171018c6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f915a6c4bb35e048cd7c79a4796a04b7",
     "grade": false,
     "grade_id": "StylisticAugmentDwld",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.InceptionV3(include_top=False, weights='imagenet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c90596",
   "metadata": {},
   "source": [
    "## Prepare Feature Extraction Model\n",
    "\n",
    "We we do not need to be concerned with the details (we will use the code as it is *off-the-shelf*), but feel free to play with the **layers** to see what effect they have on an image.\n",
    "\n",
    "The explanation of the following code is provided FYI and is taken from https://www.tensorflow.org/tutorials/generative/deepdream#prepare_the_feature_extraction_model.\n",
    "\n",
    "> ...the layers of interest are those where the convolutions are concatenated. There are 11 of these layers in InceptionV3, named 'mixed0' though 'mixed10'. Using different layers will result in different dream-like images. Deeper layers respond to higher-level features (such as eyes and faces), while earlier layers respond to simpler features (such as edges, shapes, and textures). Feel free to experiment with the layers selected below, but keep in mind that deeper layers (those with a higher index) will take longer to train on since the gradient computation is deeper.\n",
    "\n",
    "> The complexity of the features incorporated depends on layers chosen by you, i.e, lower layers produce strokes or simple patterns, while deeper layers give sophisticated features in images, or even whole objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c286b2",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "f35ef390d02bb7e16e30e2676bd7e1a5",
     "grade": false,
     "grade_id": "ChooseLayers",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Maximize the activations of these layers\n",
    "names = ['mixed3', 'mixed5']\n",
    "layers = [base_model.get_layer(name).output for name in names]\n",
    "\n",
    "# Create the feature extraction model\n",
    "dream_model = tf.keras.Model(inputs=base_model.input, outputs=layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1735b432",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "46e093d6a6cf128d98195341e781389f",
     "grade": false,
     "grade_id": "CalculateLoss",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Calculate Loss\n",
    "\n",
    "The following is from https://www.tensorflow.org/tutorials/generative/deepdream#calculate_loss.\n",
    "Again, we aren't concerned with the details and will use the code as it is.\n",
    "\n",
    "> The **loss** is the sum of the activations in the chosen layers. The loss is normalized at each layer so the contribution from larger layers does not outweigh smaller layers. Normally, *loss is a quantity you wish to minimize via gradient descent*. In **DeepDream**, you will *maximize this loss via gradient ascent*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79394afc",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "4485731109e26d5d4341a3854875dac6",
     "grade": false,
     "grade_id": "CalculateLoss-Code",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss(img, model):\n",
    "    # Pass forward the image through the model to retrieve the activations.\n",
    "    # Converts the image into a batch of size 1.\n",
    "    img_batch = tf.expand_dims(img, axis=0)\n",
    "    layer_activations = model(img_batch)\n",
    "    if len(layer_activations) == 1:\n",
    "        layer_activations = [layer_activations]\n",
    "\n",
    "    losses = []\n",
    "    for act in layer_activations:\n",
    "        loss = tf.math.reduce_mean(act)\n",
    "        losses.append(loss)\n",
    "\n",
    "    return tf.reduce_sum(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb875bc6",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "28d407fcd0ef00d6e14ff3ff24ff1882",
     "grade": false,
     "grade_id": "GradientAscent",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Gradient Ascent\n",
    "\n",
    "The following is from https://www.tensorflow.org/tutorials/generative/deepdream#gradient_ascent.\n",
    "Again, we aren't concerned with the details and will use the code as it is.\n",
    "\n",
    "> After the loss for the chosen layers is calculated, calculate the gradients with respect to the image and add them to the original image.\n",
    "Adding the gradients to the image **enhances the patterns seen by the neural network**. At each step, we create an image that **increasingly excites the activations of certain layers** in the network.\n",
    "\n",
    "> The method that does this is wrapped in a `tf.function` for performance. It uses an `input_signature` to ensure that the function is not retraced for different image sizes or `steps/step_size` values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f8f09d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "15ce5cd0af367833ae970f1811fb2f0c",
     "grade": false,
     "grade_id": "DeepDreamCode",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DeepDream(tf.Module):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    @tf.function(\n",
    "        input_signature=(\n",
    "            tf.TensorSpec(shape=[None,None,3], dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=[], dtype=tf.int32),\n",
    "            tf.TensorSpec(shape=[], dtype=tf.float32),)\n",
    "    )\n",
    "    def __call__(self, img, steps, step_size):\n",
    "        print(\"Tracing\")\n",
    "        loss = tf.constant(0.0)\n",
    "        for n in tf.range(steps):\n",
    "            with tf.GradientTape() as tape:\n",
    "                # This needs gradients relative to `img`\n",
    "                # `GradientTape` only watches `tf.Variable`s by default\n",
    "                tape.watch(img)\n",
    "                loss = calc_loss(img, self.model)\n",
    "\n",
    "            # Calculate the gradient of the loss with respect to the pixels of the input image.\n",
    "            gradients = tape.gradient(loss, img)\n",
    "\n",
    "            # Normalize the gradients.\n",
    "            gradients /= tf.math.reduce_std(gradients) + 1e-8 \n",
    "\n",
    "            # In gradient ascent, the \"loss\" is maximized so that the input image increasingly \"excites\" the layers.\n",
    "            # You can update the image by directly adding the gradients (because they're the same shape!)\n",
    "            img = img + gradients*step_size\n",
    "            img = tf.clip_by_value(img, -1, 1)\n",
    "\n",
    "        return loss, img\n",
    "\n",
    "deepdream = DeepDream(dream_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0e03c",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "4332cee863c5a58cc974a76813813863",
     "grade": false,
     "grade_id": "DeepDream-MainLoop",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## DeepDream: Main Loop\n",
    "\n",
    "From https://www.tensorflow.org/tutorials/generative/deepdream#main_loop.\n",
    "Again, we are not concerned with the details and will use the code as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4110cea",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ad74e09e3b7a3ef747b532ff20eb526c",
     "grade": false,
     "grade_id": "RunDeepDream",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_deep_dream_simple(img, steps=100, step_size=0.01):\n",
    "    # Convert from uint8 to the range expected by the model.\n",
    "    img = tf.keras.applications.inception_v3.preprocess_input(img)\n",
    "    img = tf.convert_to_tensor(img)\n",
    "    \n",
    "    step_size = tf.convert_to_tensor(step_size)\n",
    "    steps_remaining = steps\n",
    "    step = 0\n",
    "    \n",
    "    while steps_remaining:\n",
    "        if steps_remaining>100:\n",
    "            run_steps = tf.constant(100)\n",
    "        else:\n",
    "            run_steps = tf.constant(steps_remaining)\n",
    "        steps_remaining -= run_steps\n",
    "        step += run_steps\n",
    "\n",
    "        loss, img = deepdream(img, run_steps, tf.constant(step_size))\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        show(deprocess(img))\n",
    "        print (\"Step {}, loss {}\".format(step, loss))\n",
    "\n",
    "    result = deprocess(img)\n",
    "    display.clear_output(wait=True)\n",
    "    show(result)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d924bd5b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "47ed21463bc12d1778c817055fe4f33e",
     "grade": false,
     "grade_id": "Processing-DeepDream",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Process an image and view the result. This should process the labrador image mentioned earlier and display the **DeepDreamed** image to the screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1c2cf",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "3de8eaa86645b3a9b4dca79f0c045ed0",
     "grade": false,
     "grade_id": "cell-251eb7316d8fe070",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "dream_img = run_deep_dream_simple(img=original_img, steps=100, step_size=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e16dc8",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a31382d508f051c689173038baced1b9",
     "grade": false,
     "grade_id": "DatasetAnalysis",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    <h2>The assignment to be submitted begins here.</h2>\n",
    "</div>\n",
    "\n",
    "\n",
    "# Generate New Image Data Via DeepDream"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f15049d",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3 style=\"text-decoration:underline;\">UPDATE</h3>\n",
    "    <p>The <strong>Cats & Dogs</strong> dataset consists of 20,000 images, which is too many to process by <strong>DeepDream</strong> (as well as taking too long to train the simpler classification models).</br>\n",
    "    Possible approach: use only 1,000 images from the original dataset (800 training, 200 testing).</p>\n",
    "    <p>One method to read the <strong>Cats & Dogs</strong> data is by using the <strong>Tensorflow-Datasets</strong> module:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a168ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "# (train_dataset, test_dataset), metadata = tfds.load(\n",
    "#     'cats_vs_dogs',\n",
    "#     split=['train[:80%]', 'train[80%:]'],\n",
    "#     with_info=True,\n",
    "#     as_supervised=True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2faa600",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3 style=\"text-decoration:underline;\">UPDATE</h3>\n",
    "    <p>Load <strong>Cats & Dogs</strong> dataset, reshape/resize, and save to a new file.</p>\n",
    "    <p><strong>Keras</strong> provides image preprocessing tools we can use.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d52015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# location of downloaded Dogs vs. Cats image dataset on my computer\n",
    "#folder = '/Volumes/WDBook/dogs-vs-cats/train/'\n",
    "\n",
    "# subset of original dataset consisting of 1,000 images\n",
    "folder = \"/Users/cyrus/tensorflow_datasets/cats_vs_dogs/train1000/\"\n",
    "# subset of original dataset consisting of 10,000 images\n",
    "#folder = '/Volumes/WDBook/dogs-vs-cats/train-10000/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c81d7a22",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4 style=\"text-decoration:underline;\">UPDATE</h4>\n",
    "    <p>Because the images in the dataset are of many different dimensions, we will need to resize the images so they are all 200x200 pixels.</br>\n",
    "    This transformation will result in distorting, stretching, etc. every image to conform to a 200x200 image.</p>\n",
    "    <p></p>\n",
    "    <p>Sample code to resize/reshape images:</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f920359f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.preprocessing.image import load_img\n",
    "# resized_photo = load_img(\"/path/to/original_image_file\", target_size=(200, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21051c3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4 style=\"text-decoration:underline;\">UPDATE</h4>\n",
    "    Convert the resized image to a Python array:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd766d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resized_photo = img_to_array(resized_photo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc21fb62",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h4 style=\"text-decoration:underline;\">UPDATE</h4>\n",
    "    <p>After resizing the images, calculate the amount of memory (RAM) the computer will require to process the entire <strong>Cats & Dogs</strong> image dataset.</p>\n",
    "    <h4 style=\"text-decoration:underline;\">Size Of Dataset With 20,000 Images</h4>\n",
    "    <p>Using all <strong>20,000 images</strong> of the original dataset:</br>\n",
    "    20,000 images <strong>x</strong> 200 x 200 x 3 pixels per image</br>\n",
    "     = 2,400,000,000 32-bit pixels</br>\n",
    "     = 76,800,000,000 bits</br>\n",
    "     = 9,600,000,000 bytes (conversion: 8 bits in 1 byte)</br>\n",
    "     = <strong>9.6 Gbytes</strong></p>\n",
    "    <p></br></p>\n",
    "    <h4 style=\"text-decoration:underline;\">Size Of Dataset With 1,000 Images</h4>\n",
    "    <p>Using only <strong>1,000 resized images</strong> from the original dataset:</br>\n",
    "    1,000 images <strong>x</strong> 200 x 200 x 3 pixels per image</br>\n",
    "     = 120,000,000 32-bit pixels = 3,840,000,000 bits = 480,000,000 bytes</br>\n",
    "     = <strong>0.48 Gb</strong></p>\n",
    "    <p></br></p>\n",
    "    <h4 style=\"text-decoration:underline;\">Size Of Dataset With 10,000 Images</h4>\n",
    "    <p>Using <strong>10,000 resized images</strong> from the original dataset:</br>\n",
    "    10,000 images <strong>x</strong> 200 x 200 x 3 pixels per image</br>\n",
    "     = 1,200,000,000 32-bit pixels = 38,400,000,000 bits = 4,800,000,000 bytes</br>\n",
    "     = <strong>4.8 Gb</strong></p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79d7dbb",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "    <h3 style=\"text-decoration:underline;\">NOTE</h3>\n",
    "    <p>If the dataset is larger than the amount of available <strong>RAM</strong>, then Jupyterlab will display a message similar to:</br>\n",
    "    \"The kernel for A2.ipynb appears to have died. It will restart automatically.\"</p>\n",
    "    <p></p>\n",
    "    Successful execution of the below code will display something similar to:</br>\n",
    "    (1000, 200, 200, 3) (1000,)</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601d4e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "photos, labels = list(), list()\n",
    "\n",
    "# processing every file in a folder\n",
    "for file in listdir(folder):\n",
    "\t# determine label of image from filename (cat = 1, dog = 0)\n",
    "\toutput = 0.0 \n",
    "\tif file.startswith('cat'):\n",
    "\t\toutput = 1.0\n",
    "\t\n",
    "\tphoto = load_img(folder + file, target_size=(200, 200))\n",
    "    \n",
    "\t# convert image to a Python array\n",
    "\tphoto = img_to_array(photo)\n",
    "\t\n",
    "    # store converted image & its corresponding output label\n",
    "\tphotos.append(photo)\n",
    "\tlabels.append(output)\n",
    "\n",
    "# converts list of images to a Python array\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "\n",
    "# print(photos.shape, labels.shape)\n",
    "\n",
    "# save resized photos to avoid having to repeat the above process\n",
    "save('/Users/cyrus/tensorflow_datasets/cats_vs_dogs/dogs_vs_cats_photos.npy', photos)\n",
    "save('/Users/cyrus/tensorflow_datasets/cats_vs_dogs/dogs_vs_cats_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f49bd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    <h3 style=\"text-decoration:underline;\">UPDATE</h3>\n",
    "    Load the saved reshaped images then confirm their shape (i.e., dimension).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c211bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import load\n",
    "\n",
    "photos = load('/Users/cyrus/tensorflow_datasets/cats_vs_dogs/dogs_vs_cats_photos.npy')\n",
    "labels = load('/Users/cyrus/tensorflow_datasets/cats_vs_dogs/dogs_vs_cats_labels.npy')\n",
    "\n",
    "print(photos.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bcc5bd",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0856c4a413ceb3ec832fe982daca7ea2",
     "grade": false,
     "grade_id": "DatasetAnalysisBonus",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Analysis Of Dataset BONUS (5 Marks)\n",
    "\n",
    "Provide empirical information about the Cats & Dogs dataset.\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <h4>BONUS</h4>\n",
    "    Write code to provide empirical information about the <strong>Cats & Dogs</strong> dataset. Use visual elements where possible.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf0ce0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5bce529bf412a8374518ed3d15a8954c",
     "grade": true,
     "grade_id": "DatasetAnalysisBonus-Code",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import IPython.display as display\n",
    "from PIL import Image\n",
    "cat = Image.open(r'C:\\Users\\cyrus\\tensorflow_datasets\\cats_vs_dogs\\train1000\\cat(1).jpg')\n",
    "dog = Image.open(r'C:\\Users\\cyrus\\tensorflow_datasets\\cats_vs_dogs\\train1000\\dog(1).jpg')\n",
    "display.display(cat)\n",
    "display.display(dog)\n",
    "\n",
    "photos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803e2e3d",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "be88b5263ae9c17e54601494b3cd4964",
     "grade": false,
     "grade_id": "CreateTestTrainDatasets",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Create Testing & Training Datasets (5 Marks)\n",
    "\n",
    "Separate the **Cats & Dogs** dataset into a test set and a training set.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    Write the code to separate the data into a test set and a training set below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b2c392",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bb6e26bced217ccddb73b1d7c0ce9ca1",
     "grade": true,
     "grade_id": "cell-CreateTestTrainDatasets",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(photos, labels, test_size=0.33, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677aea1d",
   "metadata": {},
   "source": [
    "### Process Testing Dataset Via DeepDream (10 Marks)\n",
    "\n",
    "Create a **DeepDreamed Test Set** by processing the original test set via **DeepDream**. Display a few of the resulting **DeepDreamed** images.\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    Write the code that processes images via <strong>DeepDream</strong> below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42aac525",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2065e55497478239dd3dcfbb6233b420",
     "grade": true,
     "grade_id": "DeepDreamTheTestSet",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "import copy\n",
    "deepDreamTest = []\n",
    "\n",
    "X_testCopy = copy.deepcopy(X_test)\n",
    "for image in X_testCopy:\n",
    "    newimg = run_deep_dream_simple(img=image, steps=100, step_size=0.01)\n",
    "    deepDreamTest.append(newimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b933f277",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f5d6c682312f18ccd81b18a0d2d1e011",
     "grade": false,
     "grade_id": "StyleTransfer-BONUS",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Style Transfer BONUS (10 Marks)\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    <p>Process the test set using <a href=\"https://www.tensorflow.org/tutorials/generative/style_transfer\">Style Transfer</a>.</p>\n",
    "    <p>Display a few images processed using <strong>Style Transfer</strong>.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e78069",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b3fe8023f152718194f025b12c7b3c6d",
     "grade": true,
     "grade_id": "StyleTransfer-BONUS-code",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "for img in deepDreamTest[:5]:\n",
    "    show(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ee2d02",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d97c884d9625a0c0fdbb46e045d9bfc",
     "grade": false,
     "grade_id": "EvaluateSingleModels",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Evaluating Individual Models (10 Marks)\n",
    "\n",
    "The following classification models are to be evaluated (default parameters can be used in both models):\n",
    "* [SVM classifier](https://scikit-learn.org/stable/modules/svm.html#classification) \n",
    "* [decision tree classifier](https://scikit-learn.org/stable/modules/tree.html#classification)\n",
    "\n",
    "\n",
    "Models will be *trained* on the **training data**.\n",
    "\n",
    "Two *separate evaluations* will be performed:\n",
    "* models will be evaluated on the **original test data**\n",
    "* models will be evaluated on the **transformed test data**\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    Write the code below to create and evaluate the classifiers.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    <h4>TIP</h4>\n",
    "    Classifiers take two arrays as input:</br>\n",
    "    <strong>array X</strong> of shape (number_of_samples, number_of_features) containing the training samples feature data</br>\n",
    "    <strong>array y</strong> of class labels (strings or integers) of shape (number_of_samples)</p>\n",
    "    <p></p>\n",
    "    <p>print(photos.shape, labels.shape)</br>\n",
    "    num_samples = labels.shape[0]</br>\n",
    "    x = np.reshape(photos, (num_samples, -1))</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef8ada9",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "b0ab4b4e978cfa368bb6946bcb0abc6a",
     "grade": true,
     "grade_id": "EvaluateSingleModels-Code",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Code to convert RGB image into a NumPy array for input to a classifier model\n",
    "print(X_train.shape, y_train.shape)\n",
    "num_samples = y_train.shape[0]\n",
    "test_samples = y_test.shape[0]\n",
    "X_trainShaped = np.reshape(X_train, (num_samples, -1))\n",
    "deepDream_testShaped = np.reshape(deepDreamTest, (test_samples, -1))\n",
    "X_testShaped = np.reshape(X_test, (test_samples, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf15835",
   "metadata": {},
   "source": [
    "##### SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d28b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM classifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "SVM = svm.SVC()\n",
    "# Train model with training data\n",
    "SVM.fit(X_trainShaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f5e16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using original test data\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import metrics\n",
    "\n",
    "y_pred = SVM.predict(X_testShaped)\n",
    "SVMOrigACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ce6e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMOrigACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e0c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "SVMOrigConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3ad761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using transformed test data\n",
    "y_pred = SVM.predict(deepDream_testShaped)\n",
    "SVMTransACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170a17f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMTransACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b834a0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMTransConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94aa5442",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMScores = cross_val_score(SVM, deepDream_testShaped + X_testShaped, y_test + y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26e366d",
   "metadata": {},
   "source": [
    "#### Decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96328761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree classifier\n",
    "from sklearn import tree\n",
    "\n",
    "DTC = tree.DecisionTreeClassifier()\n",
    "# Train model with training data\n",
    "DTC.fit(X_trainShaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac9ab78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using original test data\n",
    "y_pred = DTC.predict(X_testShaped)\n",
    "DTCOrigACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3922ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCOrigACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a62d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCOrigConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad36891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using transformed test data\n",
    "y_pred = DTC.predict(deepDream_testShaped)\n",
    "DTCTransACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9487428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCTransACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e9e5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCScores = cross_val_score(DTC, deepDream_testShaped + X_testShaped, y_test + y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2f3af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTCTransConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa3735",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the tree\n",
    "tree.plot_tree(DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63736db0",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "0261d7bc7c70261c8965eae920694c06",
     "grade": false,
     "grade_id": "CreateEnsembles",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Create Ensemble Models\n",
    "\n",
    "View the lecture videos for a *brief* explanation of ensemble models. Scikit-learn provides a [concise explanation of ensembles](https://scikit-learn.org/stable/modules/ensemble.html#ensemble)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9648915",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "95e68b75a06e930660b55690c6c2d8aa",
     "grade": false,
     "grade_id": "CreateRandom",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Random Forest (5 Marks)\n",
    "\n",
    "The **scikit-learn** implementation of **Random Forest** \"*combines classifiers by averaging their probabilistic prediction, instead of letting each classifier vote for a single class*\".\n",
    "\n",
    "Code examples for implementing a **Random Forest Classifiers** are [here](https://scikit-learn.org/stable/modules/ensemble.html#forest).\n",
    "API information on **Random Forest Classifiers** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html#sklearn.ensemble.RandomForestClassifier).\n",
    "\n",
    "Using **scikit-learn**, create a **Random Forest** classifier consisting of the following parameters (model parameters not specified can be left to their default values):\n",
    "* number of estimators = 100\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    Write the code to create a Random Forest classifier ensemble below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970318b",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "ff475a57a607ca0ebb7a51b626905a8b",
     "grade": true,
     "grade_id": "RandomForest-Code",
     "locked": false,
     "points": 5,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RFC = RandomForestClassifier(n_estimators=100)\n",
    "RFC.fit(X_trainShaped, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbef4fe",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "c4b64efb911801f8de3b008343eb6f60",
     "grade": false,
     "grade_id": "CreateVoting",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Voting Ensemble (10 Marks)\n",
    "\n",
    "A **Voting Ensemble** classifier \"*combine conceptually different machine learning classifiers and use a majority vote (hard vote) or the average predicted probabilities (soft vote) to predict the class labels*\".\n",
    "\n",
    "Using **scikit-learn**, create two **Voting Ensemble Classifiers** (*hard voting* and *soft voting*) consisting of the models created in the previous sections (**Evaluating Individal Models**, etc.):\n",
    "* SVM classifier\n",
    "* decision tree classifier\n",
    "* Random Forest classifier\n",
    "\n",
    "Use the default parameters for both *hard voting* and *soft voting* classifiers.\n",
    "\n",
    "Code examples for implementing a **Voting Ensemble Classifier** is [here](https://scikit-learn.org/stable/modules/ensemble.html#voting-classifier).\n",
    "API information on **Voting Ensemble Classifier** is [here](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.VotingClassifier.html#sklearn.ensemble.VotingClassifier).\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    Write the code to create a Voting Ensemble classifier below.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d28fee",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "dd735b4f88ccc27ab48d192456f25df0",
     "grade": true,
     "grade_id": "Voting-Code",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Hard voting\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "VCHard = VotingClassifier(estimators=[('SVM', SVM), ('Tree', DTC), ('Forest', RFC)], \n",
    "                          voting='hard')\n",
    "VCHard.fit(X_trainShaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b64c259",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up new SVM to adjust for soft voting\n",
    "SVMSoft = svm.SVC(probability=True)\n",
    "SVMSoft.fit(X_trainShaped, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a45a422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soft voting\n",
    "VCSoft = VotingClassifier(estimators=[('SVM', SVMSoft), ('Tree', DTC), ('Forest', RFC)], \n",
    "                          voting='soft')\n",
    "VCSoft.fit(X_trainShaped, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b155146e",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "26323ff580bc87e6109c6e9886c47c25",
     "grade": false,
     "grade_id": "EvaluateEnsembles",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "toc-hr-collapsed": true
   },
   "source": [
    "# Evaluate Ensembles (10 Marks)\n",
    "\n",
    "Models will be *trained* on the **training data**.\n",
    "\n",
    "Two *separate evaluations* will be performed:\n",
    "* ensemble model will be evaluated on the **original test data**\n",
    "* ensemble model will be evaluated on the **transformed test data**\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>WRITE CODE</h4>\n",
    "    Write the code below to evaluate the ensembles on the test data.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e695e5",
   "metadata": {},
   "source": [
    "#### Random Forest evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3abcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using original test data\n",
    "y_pred = RFC.predict(X_testShaped)\n",
    "RFCOrigACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a95033",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFCOrigACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b10526",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFCOrigConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ee02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFCScores = cross_val_score(RFC, deepDream_testShaped + X_testShaped, y_test + y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176714d0",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "aad1e29819351e4e5051977fc9a69794",
     "grade": true,
     "grade_id": "EvaluateEnsembles-Code",
     "locked": false,
     "points": 10,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Evaluating using transformed test data\n",
    "y_pred = RFC.predict(deepDream_testShaped)\n",
    "RFCTransACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ac865",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFCTransACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d396d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFCTransConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb91cb6e",
   "metadata": {},
   "source": [
    "#### Hard voting evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f3e6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using original test data\n",
    "y_pred = VCHard.predict(X_testShaped)\n",
    "VCHardOrigACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc935022",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCHardOrigACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551c4198",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCHardOrigConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00f1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using transformed test data\n",
    "y_pred = VCHard.predict(deepDream_testShaped)\n",
    "VCHardTransACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888c29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCHardTransACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c226eef",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCHardTransConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31de2d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCHardScores = cross_val_score(VCHard, deepDream_testShaped + X_testShaped, y_test + y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ddf68a0",
   "metadata": {},
   "source": [
    "#### Soft voting evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cb6952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using original test data\n",
    "y_pred = VCSoft.predict(X_testShaped)\n",
    "VCSoftOrigACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9f70b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCSoftOrigACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6cfb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCSoftOrigConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a483a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using transformed test data\n",
    "y_pred = VCSoft.predict(deepDream_testShaped)\n",
    "VCSoftTransACC = metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04ce74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCSoftTransACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5d153b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCSoftTransConf = confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636c0a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCSoftScores = cross_val_score(VCSoft, deepDream_testShaped + X_testShaped, y_test + y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ccca3f",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "e9667edc3a174becc395d1b5dcb8ee8e",
     "grade": false,
     "grade_id": "Discussion",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": [],
    "toc-hr-collapsed": true
   },
   "source": [
    "# Discussion Of Results (40 Marks)\n",
    "\n",
    "Discuss the results similar to **Coding Assignment #1** (using charts and graphs where possible).\n",
    "Compare the performance of the various models.\n",
    "Was the performance what you expected?\n",
    "\n",
    "Which system performed best? Why?\n",
    "Which system had the worst performance? Why?\n",
    "\n",
    "Provide some ideas to try that could improve the performance of the models (i.e., *Future Work*).\n",
    "\n",
    "<div class=\"alert alert-danger\">\n",
    "    <h4>DISCUSSION</h4>\n",
    "    <p>Provide your <strong>Discussion Of Results</strong> below. Use visual elements where possible.</p>\n",
    "    <p>Feel free to include both <em>Markdown</em> cells and <em>Code</em> cells where necessary.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a9d7be",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d8bf01bef78e1a2dacdbba4f2d1e7454",
     "grade": false,
     "grade_id": "cell-0bcc5e15e720751a",
     "locked": true,
     "points": 40,
     "schema_version": 3,
     "solution": false,
     "task": true
    }
   },
   "source": [
    "### BEGIN ANSWER\n",
    "\n",
    "### END ANSWER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181641d1",
   "metadata": {},
   "source": [
    "With each model used, performace was measured through 3 different metrics; accuracy, cross validation, and confusion matrix.<br>\n",
    "Accuracy was used since the dataset is known to have exact same number of cat pictures and dog pictures. When data is split in to training and testing sets, the probability of having extremely skewed or biased sets is very low. Having balanced datasets is required to ensure the accuracy metric is reliable and accurate. <br>\n",
    "Cross validation was used for a couple different reasons. One of the biggest is to use all data possible in the dataset to evaluate the model instead of just train and test sets. To save time and resources, the original cats_vs_dogs dataset contained 20,000 photos, but this assignment only used 1002 of those photos. Another reason is to avoid overfitting of models. Since cross validation will train and test with all data in the set rather than just the train and test split, the process will show if the model was overfitted with much lower scores. <br>\n",
    "Confusion matrix was used to visual exactly how many correct predictions, incorrect prediction, and the type of errors that were committed. Having this visual will help with optimizing models with different parameters to adjust for the errors. <br>\n",
    "<br>\n",
    "To begin with the results, the accuracy score between the original test data and transformed test data were almost the same with each model. Most of the time, the accuracy of the original test data is slightly higher than the transformed images. This result is to be expected since transformed images were not a part of the training set, so all transformed data is like complete different and new images not very similar to regular cats and dogs.\n",
    "<br>\n",
    "All accuracy scores from the invididual models SVM classfier and Decision tree classifier in the graph below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d77833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "models = ['SVM Original', 'SVM Transformed', 'Decision Tree Original', 'Decision Tree Transformed']\n",
    "accuracy = [SVMOrigACC, SVMTransACC, DTCOrigACC, DTCTransACC]\n",
    "ax.bar(models,accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d794ec",
   "metadata": {},
   "source": [
    "SVM with the original data has the highest score but it only beats the other models by a little bit. Both decision tree predictions share the lowest score as the difference between them is less than 0.004. I expected the performance of the original data to be much higher than its counter part of transformed data. This would make sense because each model was trained and fitted on the original pictures without transformations, so it would better predict other original pictures well and be unable to predict transformed pictures very well. However, the accuracy scores states otherwise where all scores are almost the same. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c1f172",
   "metadata": {},
   "source": [
    "All accuracy scores from the ensemble models Random forest, Hard vote, and Soft vote are given below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62111b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "models = ['Forest Original', 'Forest Transformed', 'Hard Vote Original', 'Hard Vote Transformed', \n",
    "          'Soft Vote Original' ,'Soft Vote Transformed']\n",
    "accuracy = [RFCOrigACC, RFCTransACC, VCHardOrigACC, VCHardTransACC, VCSoftOrigACC, VCSoftTransACC]\n",
    "ax.bar(models,accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a4eca1",
   "metadata": {},
   "source": [
    "As expected, hard vote model with the original data has the highest accuracy score. This is to be expected since it encorporated 3 different models, SVM, Decision tree, and Random forest to create a prediction. Using default parameters is a clear handicap for soft vote since the largest difference between the two voting classifiers are these weights. Since the weights of Soft voting were not specified, hard voting comes with the highest score. Even hard voting with transformed data was more accurate than all other models except for its original variant. Across all other models, the original data set scored slightly higher than transformed data, similar result as the individual models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b48d9c",
   "metadata": {},
   "source": [
    "Accuracy scores from all models can be seen in this graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a984cd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "models = ['SVM O', 'SVM T', 'D Tree O', 'D Tree T',\n",
    "          'Forest O', 'Forest T', 'H Vote O', 'H Vote T', \n",
    "          'S Vote O' , 'S Vote T']\n",
    "accuracy = [SVMOrigACC, SVMTransACC, DTCOrigACC, DTCTransACC, RFCOrigACC, RFCTransACC, \n",
    "            VCHardOrigACC, VCHardTransACC, VCSoftOrigACC, VCSoftTransACC]\n",
    "ax.bar(models, accuracy)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb75a309",
   "metadata": {},
   "source": [
    "Next we will look at cross validation scores of all models. The main difference to note between accuracy score and cross validation score is the process of how the score is achieved. 10 fold cross validation was used. Both original data and transformed data were added together, split, trained, then predicted rather than training solely on original data. Essentially all data was used together for training and testing rather than splitting the different sets.\n",
    "It is difficult to predict the difference between the cross validation scores and accuracy scores. The scores can increase since transformed data will be used in training and testing. The transformed photos will not be a completely foreign object for each model. However there can be a decrease because these photos can also skew and ruin training data since there is less consistency throughout each photo. The model may not have enough photos to learn especially since there are much less transformed photos than original photos.<br>\n",
    "10 fold cross validation scores of all models can be seen in the graph below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ae10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = [SVMScores, DTCScores, RFCScores, VCHardScores, VCSoftScores]\n",
    "names = ['SVM', 'Decision Tree', 'Random Forest', 'Hard Vote', 'Soft Vote']\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0,0,2,1])\n",
    "plt.boxplot(scores, labels=names, showmeans=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408c49eb",
   "metadata": {},
   "source": [
    "This box plot shows how similar each model is in terms of cross validation score since all medians overlap. The highest mean showcased by the green triangle which seems to be both SVM and Hard vote classifiers. Random forest has the tighest mean as shown with the smallest box which means most of its scores were very similar compared to decision tree classifier which has a large box and whisker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d55d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('SVM original\\n',  SVMOrigConf)\n",
    "print('SVM transformed\\n',  SVMTransConf)\n",
    "print('Decision tree original\\n',  DTCOrigConf)\n",
    "print('Decision tree transformed\\n',  DTCTransConf)\n",
    "print('RFC original\\n',  RFCOrigConf)\n",
    "print('RFC transformed\\n',  RFCTransConf)\n",
    "print('Hard vote original\\n',  VCHardOrigConf)\n",
    "print('Hard vote transformed\\n',  VCHardTransConf)\n",
    "print('Soft vote original\\n',  VCSoftOrigConf)\n",
    "print('Soft vote transformed\\n',  VCSoftTransConf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854f5c0",
   "metadata": {},
   "source": [
    "In these confusion matrix, the top left number and the bottom right number are the correct predictions while the other numbers are the incorrect predictions. Both hard vote classifiers with original data and transformed data seem to have out performed all other models with SVM original and transformed trailing close behind. All other models performed about the same reaching around 90 correct predictions for both labels. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49f52ac",
   "metadata": {},
   "source": [
    "Overall, the hard vote classifier performed the best according to all metrics presented above. This was expected since this classifier uses all other models presented (except for its counter part soft voting) to optimize and balance the strengths and weaknesses of each model. The worst performing model was the decision tree where the predictions made on the original data set was actually worse than predictions made on the transformed data set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e935599a",
   "metadata": {},
   "source": [
    "There could be many ways to improve each prediction model. The easiest solution could be to increase the size of the data set so that models can  be trained with more photos and make predictions on more photos. Some issues this may cause would be the amount of time and resources it would require. Already while using this data set, it takes a long time to transform each photo, to fit the model, and calculate the predictions. <br>\n",
    "Another improvement that could be made is to include some parameters for each model. The model that performed the worst, the decision tree model could highly benefit from this. Some limits to the depth of the tree may improve the performance since it would stop looking at the specifics and focus more on larger parts of the photo. When attempting to read the tree created, it is impossible to follow along with all the different branches, values, and leaves it created.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fa0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree.plot_tree(DTC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da5c1a9",
   "metadata": {},
   "source": [
    "In terms of parameters, soft voting could have been improved with the use of custom weights. Soft voting is based around weighted average probabilities, using weights to put importance on significant values, but none were used according to requirements. Figuring out the optimal weights to use however would not be as simple as inputting random numbers and it is unclear on how to input the best weights for better results. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29884aec",
   "metadata": {},
   "source": [
    "One key thing to note is all data is based on one iteration of split data. All of these scores can change depending on what images were selected for training, testing, and transformed. Since all scores were so similar, these scores will change and performance of each model can increase and decrease greatly. For example, another iteration could result in the decision tree performing the best with highest scores while hard voting may be the worst depending on data. On top of this, the entire data set was manually selected with the first 501 cat images and 501 dog images selected in the original cats vs dogs data set that contained 20,000 photos. If different photos were to be selected, that can result in different scores leading to different performance rankings. Again, this is only a concern since all scores were essentitally less than 0.1 points away from one another. There was no clear model that performed much better, and there was not a clear model that performed the worst. All models performed at a very similar level which could be attributed to computation error or measurement error. The slight differences might show insight on what model to focus on and optimize if that is a consideration in the future."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (other-env)",
   "language": "python",
   "name": "other-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
